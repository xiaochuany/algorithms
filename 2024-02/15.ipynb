{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7786d0-146b-4e10-bf25-991bdea21005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(ids):\n",
    "    counts = {}\n",
    "    for a,b in zip(ids,ids[1:]):\n",
    "        counts[(a,b)] = counts.get((a,b),0) + 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b834d-7c7e-4f89-a733-ed4f80952b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 2): 2, (2, 1): 2, (1, 3): 1}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats([1,2,1,2,1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df8b33d-7152-4d55-b5db-9bff9ad544dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(ids, pair, idx):\n",
    "    new_ids = []\n",
    "    i = 0\n",
    "    while i<len(ids):\n",
    "        if i<len(ids)-1 and ids[i]==pair[0] and ids[i+1]==pair[1]:\n",
    "            new_ids.append(idx)\n",
    "            i += 2\n",
    "        else: \n",
    "            new_ids.append(ids[i])\n",
    "            i += 1\n",
    "    return new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a8ea4-57f8-42b6-b289-4417faa86aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 1, 3]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge([1,2,1,2,1,3], (1,2), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f4a674-6740-4dfa-bbad-6be55c460d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicTokenizer:\n",
    "    \"\"\"implememt train, encode, decode a string\"\"\"\n",
    "    def __int__(self):\n",
    "        self.merges = {} # int, int -> int\n",
    "        self.vocab = {} # int -> bytes\n",
    "\n",
    "    def train(self,s:str, vocab_size:int):\n",
    "        ids = list(s.encode('utf-8')) # list of ids in range 0, ...,255\n",
    "        assert vocab_size>255\n",
    "        n_merges = vocab_size - 256\n",
    "        merges = {}\n",
    "        vocab = {i:bytes([i]) for i in range(256)}\n",
    "        idx = 256\n",
    "        for _ in range(n_merges):\n",
    "            stats = get_stats(ids)\n",
    "            pair = max(stats, key=stats.get)\n",
    "            ids = merge(ids,pair,idx)\n",
    "            merges[pair] = idx\n",
    "            vocab[idx] = vocab[pair[0]]+vocab[pair[1]]\n",
    "            idx+=1\n",
    "        self.merges = merges\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def decode(self,ids)-> str:\n",
    "        b = b\"\".join(self.vocab[i] for i in ids)\n",
    "        return b.decode(\"utf-8\")\n",
    "\n",
    "    def encode(self,s:str)->list[int]:\n",
    "        ids = list(s.encode('utf-8'))\n",
    "        while len(ids)>=2:\n",
    "            stats = get_stats(ids)\n",
    "            pair = min(stats, key= lambda p: self.merges.get(p, float(\"inf\")))\n",
    "            if pair not in self.merges:\n",
    "                break\n",
    "            idx = self.merges[pair]\n",
    "            ids = merge(ids, pair, idx)\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412b957-7191-433d-bef4-6ad9e0cdf7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = BasicTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52162afa-274e-4e3f-adb5-728b4eb931f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.train('hello!', 257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c4f4c-8dbf-48c6-9884-3a88145838f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(104, 101): 256}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c9f14-f0c1-4a20-b8ba-73d6f947c77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'heh'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode([256,104])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65144143-78fb-463e-a442-980c00bdc24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[256, 121]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.encode(\"hey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ee2ea-da52-4190-84fc-25abb5c5f45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey jude'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode(tok.encode(\"hey jude\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2421b1-9d63-4a2f-ab86-d077462dd714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
